{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-08T17:48:24.855786Z",
     "start_time": "2025-06-08T17:48:13.742655Z"
    }
   },
   "source": [
    "import torch\n",
    "from model import *\n",
    "from Debugging.Encoding.model import MaskedSelfAttention\n",
    "from tokenizer import BytePairTokenizer, TikToken4o"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "byte_training/tok.json\n",
      "loaded a model with  4201 vocabulary!\n",
      "target vocab size is:  None !\n",
      "Displaying the sequence task!\n",
      "Decoded Inputs:\n",
      "<|unknown|>Title: S\n",
      "Title: Sim\n",
      "itle: Simple\n",
      "le: Simple S\n",
      "\n",
      "Decoded Targets:\n",
      "Title: Sim\n",
      "itle: Simple\n",
      "le: Simple S\n",
      ": Simple Sab\n",
      "byte_training/tok.json\n",
      "loaded a model with  4201 vocabulary!\n",
      "target vocab size is:  None !\n",
      "Displaying the sequence task!\n",
      "Decoded Inputs:\n",
      "<|unknown|>Title: S\n",
      "Title: Sim\n",
      "itle: Simple\n",
      "le: Simple S\n",
      "\n",
      "Decoded Targets:\n",
      "Title: Sim\n",
      "itle: Simple\n",
      "le: Simple S\n",
      ": Simple Sab\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T17:48:24.982377Z",
     "start_time": "2025-06-08T17:48:24.860970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import math\n",
    "from tokenizer import BytePairTokenizer\n",
    "\n",
    "# --- Hyperparameters and Data ---\n",
    "h_dim = 18\n",
    "d_out = 16\n",
    "max_length = 6\n",
    "\n",
    "# Initialize tokenizer and embedding layer\n",
    "tokenizer = BytePairTokenizer(vocab_file='byte_training/tok.json')\n",
    "vocab_size = max(tokenizer.vocab.values()) + 2\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, h_dim, padding_idx=0)\n",
    "\n",
    "# --- Positional Encoding ---\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, max_length, h_dim):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = torch.nn.Embedding(max_length, h_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_length)\n",
    "        seq_length = x.size(1)\n",
    "        positions = torch.arange(seq_length, device=x.device).unsqueeze(0).expand_as(x)\n",
    "        return self.pos_embedding(positions)\n",
    "\n",
    "# --- Encoding Module (Embeddings + PositionalEncoding) ---\n",
    "class Encoding(torch.nn.Module):\n",
    "    def __init__(self, embedding_layer, pos_encoding):\n",
    "        super().__init__()\n",
    "        self.embedding = embedding_layer\n",
    "        self.pos_encoding = pos_encoding\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        pos_embeds = self.pos_encoding(x)\n",
    "        return embeds + pos_embeds\n",
    "\n",
    "# --- Masked Self Attention ---\n",
    "class MaskedSelfAttention(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout=0.5, qkv_bias=True):\n",
    "        super().__init__()\n",
    "        self.W_q = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_k = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_v = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.scale = 1 / math.sqrt(d_out)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length)) * -1e9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        queries = self.W_q(x)\n",
    "        keys = self.W_k(x)\n",
    "        values = self.W_v(x)\n",
    "        attn_scores = (queries @ keys.transpose(-2, -1)) * self.scale\n",
    "        seq_len = x.size(1)\n",
    "        mask = self.mask[:seq_len, :seq_len]\n",
    "        attn_scores = attn_scores + mask\n",
    "        attn_weights = torch.nn.functional.softmax(attn_scores, dim=-1)\n",
    "        z = attn_weights @ values\n",
    "        z = self.dropout(z)\n",
    "        return z\n"
   ],
   "id": "fe0eb96a4585df3b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "byte_training/tok.json\n",
      "loaded a model with  4201 vocabulary!\n",
      "target vocab size is:  None !\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T17:48:25.325890Z",
     "start_time": "2025-06-08T17:48:25.316662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example input\n",
    "phrase = 'to pimp a '\n",
    "tokens = tokenizer.encode(phrase)\n",
    "input_tensor = torch.tensor(tokens).unsqueeze(0)  # (1, seq_length)\n",
    "\n",
    "# Initialize abstract layers\n",
    "pos_encoding_layer = PositionalEncoding(max_length=max_length, h_dim=h_dim)\n",
    "encoding_layer = Encoding(embedding_layer, pos_encoding_layer)\n",
    "attention_layer = MaskedSelfAttention(d_in=h_dim, d_out=d_out, context_length=max_length)\n",
    "\n",
    "# Call them in order\n",
    "embedded_with_pos = encoding_layer(input_tensor)\n",
    "context = attention_layer(embedded_with_pos)\n",
    "\n",
    "print(\"Output shape (context):\", context.shape)\n"
   ],
   "id": "eb9893f61a1f229",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape (context): torch.Size([1, 6, 16])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T17:48:38.511725Z",
     "start_time": "2025-06-08T17:48:38.500913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyStackedFunction(torch.nn.Module):\n",
    "    def __init__(self, module_cls, N, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.modules_list = torch.nn.ModuleList([module_cls(*args, **kwargs) for _ in range(N)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [mod(x) for mod in self.modules_list]\n",
    "        return torch.stack(outputs, dim=0).squeeze()\n",
    "\n",
    "num_heads = 12\n",
    "StackedAttention = MyStackedFunction(MaskedSelfAttention, num_heads, h_dim, d_out, max_length, dropout=0.5, qkv_bias=True)"
   ],
   "id": "1587d6e45d3bec42",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T17:49:07.439278Z",
     "start_time": "2025-06-08T17:49:07.431097Z"
    }
   },
   "cell_type": "code",
   "source": "res = StackedAttention(embedded_with_pos)",
   "id": "4f629543ddb07d70",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "35970c21436e2aac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
