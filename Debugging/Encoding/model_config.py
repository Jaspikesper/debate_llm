GPT_CONFIG_124M = {

    "vocab_size": 50257,
    "context_length": 1024,
    "h_dim": 768,
    "attn_dim": 768,
    "num_heads": 12,
    "num_layers": 12,
    "dropout_rate": 0.1,
    "activation_function": "gelu",
    "attn_bias": False
}