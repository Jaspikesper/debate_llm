from urllib.request import urlretrieve
import pandas as pd
from Encoding.tokenizer import *
rawtext_link = 'https://www.gutenberg.org/ebooks/26184.txt.utf-8'
urlretrieve(rawtext_link, '../byte_training/LLM_dataset.txt')

pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)
pd.set_option('display.max_colwidth', None)

class TokenTester:

    def __init__(self, tokenizer):
        self.tokenizer = tokenizer
        self.examples = [
            ''' To create a briefer but even hotter flame, 
            ''',
            '''Bushings and other exposed electrical parts.
            ''',
            '''(1.) Spoil fruit and vegetables by leaving them in the sun.
            ''',
            '''(1) Exchange wires in switchboards containing signals and switches,
            ''',
            '''Forget tools so that you will have to go back after them.
             ''',
            '''Insert random line breaks in critical documentation files‚Äî
            ''',
            '''2) Disconnect pipes marked with "DANGER" before checking pressure...!
            ''',
            '''Leave ladders balanced on unstable surfaces (encourage collapse).
            ''',
            '''Turn OFF warning Alarms so hazards go UNNOTICED???
            ''',
            '''(3.) Jam machinery ‚Äì using incompatible components ‚â† efficiency.
            ''',
            '''never Record test failures ONLY successes; log("pass")
            ''',
            '''Apply incorrect torque‚Äîto bolts‚Äîin STRUCTURAL assemblies. (!)
            ''',
            '''Forget passwords: store in RAM, not RAM.
            ''',
            '''"Error: Unknown Exception ¬Ø\\_(„ÉÑ)_/¬Ø", ignore always.
            ''',
            '''use_variable_names = ['thing', 'stuff', 'etc.'] # seriously?
            ''',
            '''Allow RUST to fOrM by skipping *every* step of maintenance!!!
            ''',
            '''Emergency exits locked (why not?) [Security reasons]
            ''',
            '''3.5) Rewire based on vibe not blueprint üåÄüß†
            ''',
            '''(‚ö†Ô∏è Note:) Mixing reactive chemicals? try instinct!
            ''',
            '''‚ÄúLaunch sequence initiated??!‚Äù should always return: "false".
            ''',
            '''Never break `while True:` üíÄüíÄüíÄ
            ''',
            '''Use deprecated lib$‚Äîjust assume they "work".
            ''',
            '''BUGS: mark as features. Features?? as bugs ü§°.
            ''',
            '''Delay... everything. Until... the... bitter... end......
            ''',
            '''Label? Backups? Nah; ‚ÄúUntitled-3.bak.bak.bak‚Äù is fine.
            '''
        ]

        self.clipboard = pd.DataFrame(columns=['Token IDs', 'Words Decoded', 'Encoding Test'],
                                      index=range(len(self.examples)))
    def __repr__(self):
        return 'A container for tests of objects such as tokenizers. My tokenizer is: ' + self.tokenizer + ' .'

    # Test the encoder and then test the decoder of the tokenizer so that decoder(encoder(x)) produces x without exception.
    def encoder_test(self):
        for i in self.clipboard.index:
            encoded = self.tokenizer.encode(self.examples[i])
            decoded = self.tokenizer.decode(encoded)
            self.clipboard.loc[i, 'Token IDs'] = encoded
            self.clipboard.loc[i, 'Words Decoded'] = decoded
            self.clipboard.loc[i, 'Encoding Test'] = decoded.strip() == self.examples[i].strip()

if __name__ == '__main__':
 #   tokenizer = BytePairTokenizer(vocab_file=None)
    tokenizer = enc
    tester = TokenTester(tokenizer)
    tester.encoder_test()
    print(tester.clipboard)
